\section{Solutions}
\label{sec:Solution}

\subsection{Program Synthesis}

Program synthesis \cite{program-synthesis-survey} is a field that studies the
problem of automatically \textit{synthesizing} a program that can satisfy a
given \textit{specification}. Specifications may vary from informal
specifications, such as test cases, examples, or natural language, to formal
specifications, such as formal properties or logical formulas.

The characteristics of our problem make program synthesis a viable approach.
Hash functions are typically simple with a few bitwise operations, so the search
space is not too large relative to other types of programs. Through synthesis,
we can formally guarantee properties about our hash function; for example, we
may be interested in preventing strided addresses from mapping to the same
block. We can also exploit patterns in program traces in order to improve
performance for particular workloads.

\subsubsection{Problem Formulation}

To formulate the synthesis problem more precisely, suppose we have a list of
caches $C_1, C_2, \dots, C_N$ that together have a total of $2^k$ blocks. We
then label all blocks by $B_1, \dots, B_{2^k}$, so that the first $|C_1|$ blocks
are in $C_1$, the next $|C_2|$ blocks are in $C_2$, and so on. Now, we want to
synthesize a function $\mathcal{H} : \{0,1\}^n \to \{0,1\}^k$ that takes an $n$-bit
address and computes a block $B$. Using $B$, we can use the above numbering
scheme to determine which cache the address should be sent to.

This formulation is actually more general than is necessary, because we do not
actually need to compute the block number. For example, we could take the output
of $\mathcal{H}$ to directly be the cache number. However, the generality does
not hurt; for example, a future work could use the actual block numbers
themselves to account for differing associativity levels between the caches.

\subsubsection{Sketching a Hash Function}

To solve our problem, we use the method of sketching
\cite{solar-lezama-sketching}, where we define a \textit{sketch} (i.e. a
``template'') of $\mathcal{H}$ containing \textit{holes} (i.e. a
``placeholder'') that the synthesizer will be asked to \textit{complete} with
actual program fragments. We observe that $\mathcal{H}$ is usually of the
following form:
\begin{itemize}
\item $\mathcal{H}$ will select some (or all) of the input bits $b_1, \dots,
  b_n$ to use in some operations, and to which operations they should be
  provided.
\item To compute the $k$-bit hash, the selected bits must be passed through a
  composition of operations.
\end{itemize}
Thus, to compute the hash, we use $k$ holes for the output bits, where each hole
is drawn from the following grammar:

\newcommand{\bop}[1]{\mathop{\mathsf{#1}}}
\[
\begin{array}{rcl}
  H &\to& H_1 \bop{XOR} H_2 \mid H_1 \bop{AND} H_2 \mid H_1 \bop{OR} H_2
          \mid \bop{NOT} H_1 \mid b_i
\end{array}
\]

For example, one possible completion is $b_1 \dots b_n \mapsto b_1\dots b_k$,
e.g. take the first $k$ bits.

\subsubsection{Specifying Hash Behavior}

Lastly, we must define what type of specification will be used for our synthesis
problem. For simplicity, we decided on using a set of randomly generated
addresses for test cases. The test cases are chosen so that there are $|C_1|$
addresses mapped to block $C_1$, $|C_2|$ addresses mapped to block $C_2$, etc.
We then set up the synthesizer so that it attempts to find a function
$\mathcal{H}$ so that the number of test cases with expected blocks exactly
matching the output blocks of $\mathcal{H}$ is maximized. The results are shown
in the evaluation section below. While this optimization objective is naive and
simple, it leads to rather quick synthesis and serves as a good starting point
for future study.

\subsubsection{Search Strategy and Implementation}

We adopted a purely logical approach for our search strategy. We encoded the
synthesis problem as a constraint satisfaction problem that could be solved with
off-the-shelf SMT solvers. We implemented our synthesizer in the Racket
programming language using the Rosette EDSL \cite{rosette}.


\subsection{Parameterized Hash Functions}

In the previous section we looked at how to derive hash functions based on their
desired characteristics. That is, we knew what the hash function should do, but
not what it should look like. In this section we take the opposite tack, and
directly construct a hash function $\mathcal{H}$ that has the desired
properties. In this vein, we also flip our take on $\mathcal{H}$ so that we look
at it from the perspective of the caches as opposed to the memory addresses.

If we imagine each cache as a voter, with as many votes as cache lines, then a
cache could cast votes on a memory address.  We could then say whichever cache
casts the most votes for a given address wins and is the hash of that
address. This scheme is sensitive to the cache sizes from the outset. As it
stands however, the cache with the most cache lines would always cast the most
votes and would thus win every address.  In some sense, this scheme is too
sensitive to the cache sizes and we need to take a corrective action,
\textit{de-weighting} this sensitivity.

\subsubsection{Caches as Voters}
  
The maneuver we make is to arbitrarily select a distinguished cache and add a
``modifier bonus'' to it that increases the number of votes it can cast. For
instance, we could add the number 4 to the distinguished cache, giving it a
virtual 4 extra cache lines to vote with. This might make it the largest cache
which would then make it the winner of the vote as well as the hash of the
memory address.  As long as we can remember how to pick the distinguished cache
and how we derived the modifier bonus, and depending on how we choose the bonus,
the larger caches should still overall win more memory addresses, and should
fall into the distribution of base sizes.

Choosing the distinguished cache and modifier bonus can't be done
\textit{randomly} since that would make our hash function non-deterministic. But
we can choose the distinguished cache by hashing. We do this by applying a
standard, lightweight Pearson hash to the memory address, and then taking the
modulus by the number of caches, to select one cache in particular. This
strategy is deterministic and manages to always choose a pseudo-random cache,
successfully de-focusing the largest one.  A description of the algorithm is
given below.

\begin{algorithm}
  \caption{cache voting algorithm}
  \begin{algorithmic}[1]
    \REQUIRE cache\_array, a list of integers denoting corresponding cache size
    \REQUIRE pearson, an impl of the 256-bit Pearson hash function
    \REQUIRE maddr, a memory address
    \STATE distinguished\_tile $\leftarrow$ pearson(maddr) $ \% \; |cache\_array| $
    \STATE modifier\_bonus $\leftarrow$ maddr $ \% \; |cache\_array|$
    \STATE cache-array[distinguished\_tile] $+=$ modifier\_bonus
    \STATE home\_tile $\leftarrow$ argmax(cache\_array)
    \RETURN home\_tile
  \end{algorithmic}
\end{algorithm}

\subsubsection{The Modifier Bonus and Implementation }

For the modifier bonus, we can use some property of the memory address or the
data itself. We tested 3 possibilities: memory address modulo the number of
caches, sum of the positive bits in the address (popcount), and the median of
the cache sizes. This weighting component is extremely important to obtaining
good distributions of the data. We will see that the above examples are a good
first pass, but definitely need more attention in future tests.  The code was
implemented in Python without any library dependencies.

